{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae427b5-2494-4ac3-a9aa-75a9dc22ab0d",
   "metadata": {},
   "source": [
    "## Load data and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af29dc4-faac-4c75-ab33-956b0a8d4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "import os\n",
    "import mne\n",
    "import math\n",
    "import pickle\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "## Importing functions\n",
    "from mne import io, EvokedArray\n",
    "# To make a pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from mne.stats import permutation_t_test\n",
    "# To classify\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from mne.decoding import (SlidingEstimator, cross_val_multiscore, LinearModel, get_coef, Scaler, Vectorizer)\n",
    "from mne.decoding import GeneralizingEstimator\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "from mne.stats import fdr_correction\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "\n",
    "from pyriemann.estimation import ERPCovariances, XdawnCovariances, Xdawn\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import MDM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f10cc10-b47b-4f2b-aff0-35802241ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(epoch, t): #time window: 200 ms (SR=100Hz)\n",
    "    data = epoch.get_data()\n",
    "    data=data[:,:,t:t+20];\n",
    "    return data\n",
    "\n",
    "def getevents(epoch, n):\n",
    "    events = epoch.events[:,2]\n",
    "    events[events > 0] = n\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c0e42e-99ea-44ad-9466-6165da506dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eng = pd.read_excel(\"G:\\내 드라이브\\Research\\Decoding\\PsychopyViz\\stimuli_Engv.xlsx\")\n",
    "Kor = pd.read_excel(\"G:\\내 드라이브\\Research\\Decoding\\PsychopyViz\\stimuli_Korv.xlsx\")\n",
    "\n",
    "stim = []\n",
    "for i in range(64):\n",
    "    stim.append(Eng[\"word\"][i])\n",
    "    \n",
    "for i in range(64):\n",
    "    stim.append(Kor[\"word\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177b007-a22e-41bd-bfaf-c89291b81980",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECTS=['R0781', 'R0809', 'R0810', 'R0811', 'R0812', \n",
    "         'R0813', 'R0814', 'R0818', 'R0828', 'R0831',\n",
    "         'R0833', 'R0834', 'R0835', 'R0836'] #14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a22bb3-0f36-4f59-b586-62210accb127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = []\n",
    "for subject in SUBJECTS:\n",
    "    epoch = mne.read_epochs(f'CrossLingViz_EEG/noauto/{subject}_noauto_epo.fif')\n",
    "    #epochs_ref = epochs_ref.filter(h_freq=100, l_freq = 1)\n",
    "    EPOCHS.append(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723dcecd-d28e-49bd-8c45-058fc8d80917",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27396db-208e-4afb-b1bc-fab8863abc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_evoked1 = []\n",
    "ls_evoked2 = []\n",
    "ls_evoked3 = []\n",
    "ls_evoked4 = []\n",
    "\n",
    "for epochs_ref in EPOCHS:\n",
    "    r1 = re.compile(\"Eng.*goat\")\n",
    "    r2 = re.compile(\"Eng.*duck\")\n",
    "    r3 = re.compile(\"Eng.*swan\")\n",
    "    r4 = re.compile(\"Eng.*lion\")\n",
    "\n",
    "    l1 = list(filter(r1.match, stim))\n",
    "    l2 = list(filter(r2.match, stim))\n",
    "    l3 = list(filter(r3.match, stim))\n",
    "    l4 = list(filter(r4.match, stim))\n",
    "\n",
    "    evoked1 = epochs_ref[l1].average()\n",
    "    evoked2 = epochs_ref[l2].average()\n",
    "    evoked3 = epochs_ref[l3].average()\n",
    "    evoked4 = epochs_ref[l4].average()\n",
    "    ls_evoked1.append(evoked1)\n",
    "    ls_evoked2.append(evoked2)\n",
    "    ls_evoked3.append(evoked3)\n",
    "    ls_evoked4.append(evoked4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33eccda-88d2-47b0-bb4d-4d81efd2193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga1 = mne.grand_average(ls_evoked1)\n",
    "ga2 = mne.grand_average(ls_evoked2)\n",
    "ga3 = mne.grand_average(ls_evoked3)\n",
    "ga4 = mne.grand_average(ls_evoked4)\n",
    "\n",
    "ga1.comment = 'English goat'\n",
    "ga2.comment = 'English duck'\n",
    "ga3.comment = 'English swan'\n",
    "ga4.comment = 'English lion'\n",
    "\n",
    "mne.viz.plot_compare_evokeds([ga1, ga2, ga3, ga4], picks='Cz', ylim=dict(eeg=[-10, 10]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c8932-f674-4ca1-b2ef-4efaa3d9d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#200-400 KorV\n",
    "Y.plot_topomap(\n",
    "    times=[0, 1, 2, 3, 4],\n",
    "    colorbar=False,\n",
    "    size=1.5,\n",
    "    time_format=\"Pattern %d\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809964f0-d5d9-4e60-8d16-7688571e3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_evoked1 = []\n",
    "ls_evoked2 = []\n",
    "ls_evoked3 = []\n",
    "ls_evoked4 = []\n",
    "\n",
    "for epochs_ref in EPOCHS:\n",
    "    r1 = re.compile(\"Kor.*goat\")\n",
    "    r2 = re.compile(\"Kor.*duck\")\n",
    "    r3 = re.compile(\"Kor.*swan\")\n",
    "    r4 = re.compile(\"Kor.*lion\")\n",
    "\n",
    "    l1 = list(filter(r1.match, stim))\n",
    "    l2 = list(filter(r2.match, stim))\n",
    "    l3 = list(filter(r3.match, stim))\n",
    "    l4 = list(filter(r4.match, stim))\n",
    "\n",
    "    evoked1 = epochs_ref[l1].average()\n",
    "    evoked2 = epochs_ref[l2].average()\n",
    "    evoked3 = epochs_ref[l3].average()\n",
    "    evoked4 = epochs_ref[l4].average()\n",
    "    ls_evoked1.append(evoked1)\n",
    "    ls_evoked2.append(evoked2)\n",
    "    ls_evoked3.append(evoked3)\n",
    "    ls_evoked4.append(evoked4)\n",
    "\n",
    "ga1 = mne.grand_average(ls_evoked1)\n",
    "ga2 = mne.grand_average(ls_evoked2)\n",
    "ga3 = mne.grand_average(ls_evoked3)\n",
    "ga4 = mne.grand_average(ls_evoked4)\n",
    "\n",
    "ga1.comment = 'Korean goat'\n",
    "ga2.comment = 'Korean duck'\n",
    "ga3.comment = 'Korean swan'\n",
    "ga4.comment = 'Korean lion'\n",
    "\n",
    "mne.viz.plot_compare_evokeds([ga1, ga2, ga3, ga4], picks='Cz', ylim=dict(eeg=[-10, 10]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80abd06e-9d70-40f6-92c3-599f2cf4dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_evoked1 = []\n",
    "ls_evoked2 = []\n",
    "ls_evoked3 = []\n",
    "ls_evoked4 = []\n",
    "\n",
    "for epochs_ref in EPOCHS:\n",
    "    r1 = re.compile(\"Eng.*lean\")\n",
    "    r2 = re.compile(\"Eng.*cool\")\n",
    "    r3 = re.compile(\"Eng.*help\")\n",
    "    r4 = re.compile(\"Eng.*fill\")\n",
    "\n",
    "    l1 = list(filter(r1.match, stim))\n",
    "    l2 = list(filter(r2.match, stim))\n",
    "    l3 = list(filter(r3.match, stim))\n",
    "    l4 = list(filter(r4.match, stim))\n",
    "\n",
    "    evoked1 = epochs_ref[l1].average()\n",
    "    evoked2 = epochs_ref[l2].average()\n",
    "    evoked3 = epochs_ref[l3].average()\n",
    "    evoked4 = epochs_ref[l4].average()\n",
    "    ls_evoked1.append(evoked1)\n",
    "    ls_evoked2.append(evoked2)\n",
    "    ls_evoked3.append(evoked3)\n",
    "    ls_evoked4.append(evoked4)\n",
    "\n",
    "ga1 = mne.grand_average(ls_evoked1)\n",
    "ga2 = mne.grand_average(ls_evoked2)\n",
    "ga3 = mne.grand_average(ls_evoked3)\n",
    "ga4 = mne.grand_average(ls_evoked4)\n",
    "\n",
    "ga1.comment = 'English lean'\n",
    "ga2.comment = 'English cool'\n",
    "ga3.comment = 'English help'\n",
    "ga4.comment = 'English fill'\n",
    "\n",
    "mne.viz.plot_compare_evokeds([ga1, ga2, ga3, ga4], picks='Cz', ylim=dict(eeg=[-10, 10]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edac9e8f-fe46-4eea-aef3-ddf95525896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_evoked1 = []\n",
    "ls_evoked2 = []\n",
    "ls_evoked3 = []\n",
    "ls_evoked4 = []\n",
    "\n",
    "for epochs_ref in EPOCHS:\n",
    "    r1 = re.compile(\"Kor.*lean\")\n",
    "    r2 = re.compile(\"Kor.*cool\")\n",
    "    r3 = re.compile(\"Kor.*help\")\n",
    "    r4 = re.compile(\"Kor.*fill\")\n",
    "\n",
    "    l1 = list(filter(r1.match, stim))\n",
    "    l2 = list(filter(r2.match, stim))\n",
    "    l3 = list(filter(r3.match, stim))\n",
    "    l4 = list(filter(r4.match, stim))\n",
    "\n",
    "    evoked1 = epochs_ref[l1].average()\n",
    "    evoked2 = epochs_ref[l2].average()\n",
    "    evoked3 = epochs_ref[l3].average()\n",
    "    evoked4 = epochs_ref[l4].average()\n",
    "    ls_evoked1.append(evoked1)\n",
    "    ls_evoked2.append(evoked2)\n",
    "    ls_evoked3.append(evoked3)\n",
    "    ls_evoked4.append(evoked4)\n",
    "\n",
    "ga1 = mne.grand_average(ls_evoked1)\n",
    "ga2 = mne.grand_average(ls_evoked2)\n",
    "ga3 = mne.grand_average(ls_evoked3)\n",
    "ga4 = mne.grand_average(ls_evoked4)\n",
    "\n",
    "ga1.comment = 'Korean lean'\n",
    "ga2.comment = 'Korean cool'\n",
    "ga3.comment = 'Korean help'\n",
    "ga4.comment = 'Korean fill'\n",
    "\n",
    "mne.viz.plot_compare_evokeds([ga1, ga2, ga3, ga4], picks='Cz', ylim=dict(eeg=[-10, 10]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02010552-a71f-409e-a156-768d4d621163",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_evoked1 = []\n",
    "ls_evoked2 = []\n",
    "\n",
    "sg = [\"Eng_lion1\", \"Eng_lion2\", \"Eng_lion3\", \"Eng_lion4\", \n",
    "          \"Eng_goat1\", \"Eng_goat2\", \"Eng_goat3\", \"Eng_goat4\",\n",
    "          \"Eng_duck1\", \"Eng_duck2\", \"Eng_duck3\", \"Eng_duck4\", \n",
    "          \"Eng_swan1\", \"Eng_swan2\", \"Eng_swan3\", \"Eng_swan4\"]\n",
    "pl = [\"Eng_lions1\", \"Eng_lions2\", \"Eng_lions3\", \"Eng_lions4\", \n",
    "          \"Eng_goats1\", \"Eng_goats2\", \"Eng_goats3\", \"Eng_goats4\",\n",
    "          \"Eng_ducks1\", \"Eng_ducks2\", \"Eng_ducks3\", \"Eng_ducks4\", \n",
    "          \"Eng_swans1\", \"Eng_swans2\", \"Eng_swans3\", \"Eng_swans4\"]\n",
    "\n",
    "for epochs_ref in EPOCHS:\n",
    "\n",
    "    evoked1 = epochs_ref[sg].average()\n",
    "    evoked2 = epochs_ref[pl].average()\n",
    "\n",
    "    ls_evoked1.append(evoked1)\n",
    "    ls_evoked2.append(evoked2)\n",
    "\n",
    "ga1 = mne.grand_average(ls_evoked1)\n",
    "ga2 = mne.grand_average(ls_evoked2)\n",
    "\n",
    "ga1.comment = 'English singular'\n",
    "ga2.comment = 'English plural'\n",
    "\n",
    "mne.viz.plot_compare_evokeds([ga1, ga2], picks='Cz', ylim=dict(eeg=[-10, 10]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77cb1c3-2ff9-40d2-ad45-347b308dbd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_evoked1 = []\n",
    "ls_evoked2 = []\n",
    "\n",
    "sg = [\"Kor_lion1\", \"Kor_lion2\", \"Kor_lion3\", \"Kor_lion4\", \n",
    "          \"Kor_goat1\", \"Kor_goat2\", \"Kor_goat3\", \"Kor_goat4\",\n",
    "          \"Kor_duck1\", \"Kor_duck2\", \"Kor_duck3\", \"Kor_duck4\", \n",
    "          \"Kor_swan1\", \"Kor_swan2\", \"Kor_swan3\", \"Kor_swan4\"]\n",
    "pl = [\"Kor_lions1\", \"Kor_lions2\", \"Kor_lions3\", \"Kor_lions4\", \n",
    "          \"Kor_goats1\", \"Kor_goats2\", \"Kor_goats3\", \"Kor_goats4\",\n",
    "          \"Kor_ducks1\", \"Kor_ducks2\", \"Kor_ducks3\", \"Kor_ducks4\", \n",
    "          \"Kor_swans1\", \"Kor_swans2\", \"Kor_swans3\", \"Kor_swans4\"]\n",
    "\n",
    "for epochs_ref in EPOCHS:\n",
    "\n",
    "    evoked1 = epochs_ref[sg].average()\n",
    "    evoked2 = epochs_ref[pl].average()\n",
    "\n",
    "    ls_evoked1.append(evoked1)\n",
    "    ls_evoked2.append(evoked2)\n",
    "\n",
    "ga1 = mne.grand_average(ls_evoked1)\n",
    "ga2 = mne.grand_average(ls_evoked2)\n",
    "\n",
    "ga1.comment = 'Korean singular'\n",
    "ga2.comment = 'Korean plural'\n",
    "\n",
    "mne.viz.plot_compare_evokeds([ga1, ga2], picks='Cz', ylim=dict(eeg=[-10, 10]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c88aa-de85-430d-ac70-c6a2a528dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_evoked1 = []\n",
    "ls_evoked2 = []\n",
    "\n",
    "pres = [\"Eng_cools1\",\"Eng_cools2\", \"Eng_cools3\", \"Eng_cools4\", \n",
    "          \"Eng_helps1\", \"Eng_helps2\", \"Eng_helps3\", \"Eng_helps4\",\n",
    "          \"Eng_leans1\", \"Eng_leans2\", \"Eng_leans3\", \"Eng_leans4\",\n",
    "          \"Eng_fills1\", \"Eng_fills2\", \"Eng_fills3\", \"Eng_fills4\"]\n",
    "past = [\"Eng_cooled1\",\"Eng_cooled2\", \"Eng_cooled3\", \"Eng_cooled4\", \n",
    "          \"Eng_helped1\", \"Eng_helped2\", \"Eng_helped3\", \"Eng_helped4\",\n",
    "          \"Eng_leaned1\", \"Eng_leaned2\", \"Eng_leaned3\", \"Eng_leaned4\",\n",
    "          \"Eng_filled1\", \"Eng_filled2\", \"Eng_filled3\", \"Eng_filled4\"]\n",
    "\n",
    "for epochs_ref in EPOCHS:\n",
    "\n",
    "    evoked1 = epochs_ref[pres].average()\n",
    "    evoked2 = epochs_ref[past].average()\n",
    "\n",
    "    ls_evoked1.append(evoked1)\n",
    "    ls_evoked2.append(evoked2)\n",
    "\n",
    "ga1 = mne.grand_average(ls_evoked1)\n",
    "ga2 = mne.grand_average(ls_evoked2)\n",
    "\n",
    "ga1.comment = 'English present'\n",
    "ga2.comment = 'English past'\n",
    "\n",
    "mne.viz.plot_compare_evokeds([ga1, ga2], picks='Cz', ylim=dict(eeg=[-10, 10]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f9495-df38-4405-acb4-8bd88ef228db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_evoked1 = []\n",
    "ls_evoked2 = []\n",
    "\n",
    "pres = [\"Kor_cools1\",\"Kor_cools2\", \"Kor_cools3\", \"Kor_cools4\", \n",
    "          \"Kor_helps1\", \"Kor_helps2\", \"Kor_helps3\", \"Kor_helps4\",\n",
    "          \"Kor_leans1\", \"Kor_leans2\", \"Kor_leans3\", \"Kor_leans4\",\n",
    "          \"Kor_fills1\", \"Kor_fills2\", \"Kor_fills3\", \"Kor_fills4\"]\n",
    "past = [\"Kor_cooled1\",\"Kor_cooled2\", \"Kor_cooled3\", \"Kor_cooled4\", \n",
    "          \"Kor_helped1\", \"Kor_helped2\", \"Kor_helped3\", \"Kor_helped4\",\n",
    "          \"Kor_leaned1\", \"Kor_leaned2\", \"Kor_leaned3\", \"Kor_leaned4\",\n",
    "          \"Kor_filled1\", \"Kor_filled2\", \"Kor_filled3\", \"Kor_filled4\"]\n",
    "\n",
    "for epochs_ref in EPOCHS:\n",
    "\n",
    "    evoked1 = epochs_ref[pres].average()\n",
    "    evoked2 = epochs_ref[past].average()\n",
    "\n",
    "    ls_evoked1.append(evoked1)\n",
    "    ls_evoked2.append(evoked2)\n",
    "\n",
    "ga1 = mne.grand_average(ls_evoked1)\n",
    "ga2 = mne.grand_average(ls_evoked2)\n",
    "\n",
    "ga1.comment = 'Korean present'\n",
    "ga2.comment = 'Korean past'\n",
    "\n",
    "mne.viz.plot_compare_evokeds([ga1, ga2], picks='Cz', ylim=dict(eeg=[-10, 10]));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d33e28-04d3-4b04-a944-daa82d897d4f",
   "metadata": {},
   "source": [
    "## Perform temporal decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4f98d2-b7d6-4cbd-8944-2e6b1997068c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NOUNS, VERBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e92b18-bd3e-42b8-9f37-8b71ae940f41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#200 ms window\n",
    "\n",
    "a = \"Eng.*duck\"\n",
    "b = \"Eng.*goat\"\n",
    "c = \"Eng.*swan\"\n",
    "d = \"Eng.*lion\"\n",
    "\n",
    "a1 = \"Kor.*duck\"\n",
    "b1 = \"Kor.*goat\"\n",
    "c1 = \"Kor.*swan\"\n",
    "d1 = \"Kor.*lion\"\n",
    "\n",
    "e = \"Eng.*fill\"\n",
    "f = \"Eng.*cool\"\n",
    "g = \"Eng.*help\"\n",
    "h = \"Eng.*lean\"\n",
    "\n",
    "e1 = \"Kor.*fill\"\n",
    "f1 = \"Kor.*cool\"\n",
    "g1 = \"Kor.*help\"\n",
    "h1 = \"Kor.*lean\"\n",
    "\n",
    "r1 = re.compile(e)\n",
    "r2 = re.compile(f)\n",
    "r3 = re.compile(g)\n",
    "r4 = re.compile(h)\n",
    "l1 = list(filter(r1.match, stim))\n",
    "l2 = list(filter(r2.match, stim))\n",
    "l3 = list(filter(r3.match, stim))\n",
    "l4 = list(filter(r4.match, stim))\n",
    "\n",
    "listOftuples=[]\n",
    "\n",
    "for subject in SUBJECTS:\n",
    "    accuracy = []\n",
    "    epoch = mne.read_epochs(f\"CrossLingViz_EEG/noauto/{subject}_noauto_epo.fif\")\n",
    "    epoch = epoch.copy().resample(100)\n",
    "     \n",
    "    train1 = epoch[l1]\n",
    "    train2 = epoch[l2]\n",
    "    train3 = epoch[l3]\n",
    "    train4 = epoch[l4]\n",
    "\n",
    "    # Prepare train & test data\n",
    "    t = 0 #50 (100 Hz: 10 = -200ms, 30 = 0ms)\n",
    "    while t < 130:\n",
    "\n",
    "        trainx = np.concatenate((getdata(train1, t),getdata(train2, t), getdata(train3, t), getdata(train4, t)), axis=0)\n",
    "        trainy = np.concatenate((getevents(train1, 1),getevents(train2, 2), getevents(train3, 3), getevents(train4, 4)), axis=0)\n",
    "\n",
    "        train_data, train_labels = shuffle(trainx, trainy, random_state=4)\n",
    "\n",
    "        clf = make_pipeline(Xdawn(), Vectorizer(),StandardScaler(), LDA(shrinkage='auto', solver='eigen'))\n",
    "        scores = cross_val_score(clf, train_data, train_labels, cv=5, scoring='accuracy')\n",
    "\n",
    "        accuracy.append(scores.mean())\n",
    "        t += 10\n",
    "        \n",
    "    times = list(np.arange(-300,1000,100))\n",
    "    for i in range(len(times)):\n",
    "        listOftuples.append(tuple([subject, times[i], accuracy[i]]))    \n",
    "\n",
    "    df = pd.DataFrame(listOftuples, columns = ['subject', 'time', 'score']) \n",
    "\n",
    "#df.to_pickle('Temporal decoding/KVerball_lda_200ms_stand.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d675078-a342-4648-9f18-c2271ed04b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "\n",
    "plt.figure() \n",
    "ax = sns.lineplot(x = 'time', y = 'score', data = df, color='black',label='Eng nouns')\n",
    "ax.axhline(.25, color='k', linestyle='--')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('AUC')  # Area Under the Curve\n",
    "ax.axvline(.0, color='k', linestyle='dotted')\n",
    "#ax.set_xlim([-.2,.8])\n",
    "#ax.set_ylim([0.2,.35])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4a8b39-01fa-4fea-a931-c949e8890c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#permutation\n",
    "\n",
    "df1 = df\n",
    "TimesX = np.unique(df1.time)\n",
    "ENG = pd.pivot_table(df1, values = 'score', columns = 'time', index = 'subject', \n",
    "                           aggfunc={'score': np.mean}).values\n",
    "\n",
    "T_obs, clusters, cluster_p_values, H0 = \\\n",
    "    permutation_cluster_1samp_test(ENG - 0.25, n_permutations=10000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
